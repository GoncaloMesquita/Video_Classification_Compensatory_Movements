learning_rate: 2.0707823798831455e-05
hidden_size: 1
num_layers: 1
dropout: 0.16744168079390181
batch_size: 128
epochs: 200
patience: 20
delta: 0.0
clip_value: 0.8
eta: 0.0005894005426879567
threshold_label_1: 0.30000000000000004
threshold_label_2: 0.1
threshold_label_3: 0.25
threshold_label_4: 0.2
threshold_label_5: 0.15000000000000002
threshold_label_6: 0.35